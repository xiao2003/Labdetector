Metadata-Version: 2.4
Name: labdetector
Version: 1.0.0
Summary: 面向微纳流体实验室的多模态智能视觉管理系统
Author: LabDetector Team
Classifier: Programming Language :: Python :: 3
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Requires-Python: >=3.8
Description-Content-Type: text/markdown
Requires-Dist: numpy>=1.20.0
Requires-Dist: requests>=2.25.0
Requires-Dist: websockets>=10.0
Requires-Dist: Pillow>=9.0.0
Requires-Dist: opencv-python>=4.5.0
Requires-Dist: pyttsx3>=2.90
Dynamic: author
Dynamic: classifier
Dynamic: description
Dynamic: description-content-type
Dynamic: requires-dist
Dynamic: requires-python
Dynamic: summary

# 面向微纳流体实验室的多模态智能视觉管理系统 (LabDetector)

本项目面向微纳流体实验室的复杂科研环境，构建了一套涵盖边缘视觉感知、中心多模态推理、结构化知识检索与自然语音交互的智能化管理系统。

## 🔬 项目背景与系统架构

在整体系统架构设计上，本项目采取了**物理层感知终端**与**逻辑层计算中枢**相分离的分布式协同架构：

- **边缘感知节点 (Edge Perception Node)**：在实验室操作台、精密仪器区及试剂存取区等关键物理空间，密集部署基于树莓派等嵌入式计算平台的边缘感知节点。节点集成了环境光自适应调节与多帧时序预处理算法，以应对反光液面及复杂的空间遮挡问题。系统利用异步输入输出机制，通过建立持久化的 WebSocket 双向通信通道，将端到端的采集、编码与网络传输总延迟严格控制在数十毫秒级别。
- **中心推理中枢 (Central Computing Hub)**：在配备大容量显存（如 RTX 5090）的高性能计算工作站上，采用全栈本地化的方式部署数百亿参数规模的多模态视觉语言模型。充分利用 GPU 的并行计算资源，在保障模型理解精度的同时大幅压缩推理耗时，为实时图像分析提供高度稳定的算力支撑。

## 🧠 核心感知与交互决策体系

本研究方案摒弃了粗粒度的端到端图像分类模式，转而构建一套从宏观目标定位到微观姿态提取的层级化视觉解析管线：

1. **结构化视觉语义引擎**：系统引入高精度的手部关键点姿态估计算法，从连续视频帧中实时解算出操作人员双手空间关键点的精确坐标。视觉语义化转换引擎将提取到的物体包围框、空间坐标以及动作标签，按照特定的句法规则转换为结构化的自然语言描述（例如：“操作人员正在握持移液器吸取缓冲液”），彻底打破了非结构化像素数据与自然语言之间的壁垒。
2. **知识增强推理 (RAG)**：为了消除大模型在专业场景下容易产生的“事实性幻觉”，系统深度整合了检索增强生成（RAG）技术。通过预先将实验室的安全操作规范（SOP）与危险化学品理化性质表构建为专业知识向量数据库，系统能够准确判断当前的实验操作是否违规，并生成具备科学依据的指导建议。
3. **异步伴随式语音闭环**：在交互链路末端，系统集成了异步语音合成（TTS）与语音识别（ASR）技术。当系统判定存在操作风险时，能够立即中断当前流程并触发清晰的中文语音播报，确保实验人员在双手无法接触设备的无接触状态下，依然能够获得系统的实时伴随式指导。

## ⚙️ 自动化部署与技术特性

本方案在实施层面具备高度的工程可行性，系统内置了跨平台的智能化环境管理脚本，彻底解决了底层依赖缺失与环境配置门槛高的问题。

### 1. 跨平台自适应环境向导
项目重构了 `setup.py` 自动化构建脚本。在 PC 端（计算中枢）或树莓派（边缘节点）克隆本仓库后，只需于项目根目录直接执行：

```bash
python setup.py
