#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
pcside/voice/voice_interaction.py - ç‹¬ç«‹è¯­éŸ³äº¤äº’ä¸­æž¢ (æš´åŠ›å¯»éº¦ä¿®å¤ç‰ˆ)
"""
import threading
import time
import os
import sys
import json
from typing import Optional

current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(os.path.dirname(current_dir))

from pcside.core.logger import console_info, console_error
from pcside.core.config import get_config
from pcside.core.ai_backend import ask_assistant_with_rag
from pcside.knowledge_base.rag_engine import rag_engine

try:
    from pcside.core.tts import speak_async

    try:
        from pcside.core.tts import stop_tts
    except ImportError:
        def stop_tts():
            pass
except ImportError:
    def speak_async(t):
        pass


    def stop_tts():
        pass

try:
    import vosk

    vosk.SetLogLevel(-1)
    VOSK_AVAILABLE = True
except ImportError:
    VOSK_AVAILABLE = False
    console_error("æœªå®‰è£… Voskï¼Œå»ºè®®è¿è¡Œ: pip install vosk ä»¥èŽ·å¾—çº¯ç¦»çº¿è¯­éŸ³èƒ½åŠ›")

try:
    import speech_recognition as sr
    import pyaudio

    if sys.platform == 'win32':
        os.environ["PSX_NO_CONSOLE"] = "1"
    VOICE_INTERACTION_AVAILABLE = True
except ImportError as e:
    console_error(f"è¯­éŸ³äº¤äº’åŠŸèƒ½ä¸å¯ç”¨: {e}")
    sr = None;
    pyaudio = None
    VOICE_INTERACTION_AVAILABLE = False


class VoiceInteractionConfig:
    def __init__(self):
        # å¼ºåˆ¶å°†ä»Žé…ç½®æ–‡ä»¶è¯»å‡ºæ¥çš„å­—ç¬¦ä¸²è½¬æ¢ä¸ºæ­£ç¡®çš„æ•°æ®ç±»åž‹ (float / int)
        self.wake_word = str(get_config('voice_interaction.wake_word', 'å°çˆ±åŒå­¦'))
        self.wake_timeout = float(get_config('voice_interaction.wake_timeout', 10.0))
        self.wake_threshold = float(get_config('voice_interaction.wake_threshold', 0.01))
        self.energy_threshold = int(get_config('voice_interaction.energy_threshold', 300))
        self.pause_threshold = float(get_config('voice_interaction.pause_threshold', 0.8))

        # å¤„ç†åœ¨çº¿è¯†åˆ«çš„å¸ƒå°”å¼€å…³
        online_rec = get_config('voice_interaction.online_recognition', True)
        self.online_recognition = str(online_rec).lower() == 'true'

        # è·¯å¾„å¯»å€
        current_dir = os.path.dirname(os.path.abspath(__file__))
        default_model_dir = os.path.join(current_dir, 'model')
        self.vosk_model_path = str(get_config('voice_interaction.vosk_model_path', default_model_dir))


class VoiceInteraction:
    def __init__(self, config: Optional[VoiceInteractionConfig] = None):
        self.config = config or VoiceInteractionConfig()
        self.recognizer = sr.Recognizer() if sr else None
        self.microphone = None  # å»¶è¿Ÿåˆ°å¯åŠ¨æ—¶åŠ¨æ€å¯»æ‰¾
        self.is_active = False
        self.interaction_thread = None
        self.stop_event = threading.Event()
        self.last_wake_time = 0
        self.ai_backend = None
        self.is_running = False
        self.get_latest_frame_callback = None

        self.vosk_model = None
        self.vosk_recognizer = None
        self.sphinx_available = False

        self._configure_recognizer()
        self._init_offline_engine()

    def _configure_recognizer(self):
        if self.recognizer:
            self.recognizer.energy_threshold = self.config.energy_threshold
            self.recognizer.dynamic_energy_threshold = True
            self.recognizer.pause_threshold = self.config.pause_threshold
            self.sphinx_available = hasattr(self.recognizer, 'recognize_sphinx')

    def _init_offline_engine(self):
        if VOSK_AVAILABLE:
            if os.path.exists(self.config.vosk_model_path):
                try:
                    console_info(f"æ­£åœ¨åŠ è½½ Vosk ç¦»çº¿è¯­éŸ³æ¨¡åž‹...")
                    self.vosk_model = vosk.Model(self.config.vosk_model_path)
                    self.vosk_recognizer = vosk.KaldiRecognizer(self.vosk_model, 16000)
                    console_info("ç¦»çº¿è¯­éŸ³å¬å†™æ¨¡å—åŠ è½½æˆåŠŸï¼(æ”¯æŒå®Œå…¨æ–­ç½‘)")
                except Exception as e:
                    console_error(f"Voskæ¨¡åž‹åŠ è½½å¤±è´¥: {e}")

    def set_ai_backend(self, backend: str, model: str = "", api_key: Optional[str] = None):
        self.ai_backend = {"type": backend, "model": model, "api_key": api_key}

    def _recognize_audio_data(self, audio_data) -> str:
        if self.vosk_recognizer:
            try:
                raw_pcm = audio_data.get_raw_data(convert_rate=16000, convert_width=2)
                self.vosk_recognizer.AcceptWaveform(raw_pcm)
                res = json.loads(self.vosk_recognizer.FinalResult())
                text = res.get("text", "").replace(" ", "")
                if text: return text
            except Exception:
                pass

        if self.config.online_recognition and hasattr(self.recognizer, 'recognize_google'):
            try:
                return self.recognizer.recognize_google(audio_data, language="zh-CN")
            except Exception:
                pass

        return ""

    # ==========================================
    # â˜… æ ¸å¿ƒä¿®å¤ï¼šè‡ªåŠ¨å¯»æ‰¾å¯ç”¨éº¦å…‹é£Žå¹¶å¼ºåˆ¶æŽ¥ç®¡
    # ==========================================
    def _get_working_microphone(self):
        if not sr: return None
        # 1. å°è¯•é»˜è®¤é€šé“
        try:
            mic = sr.Microphone()
            with mic as source:
                pass
            return mic
        except Exception as e:
            console_error(f"é»˜è®¤å½•éŸ³é€šé“è¢«ç³»ç»Ÿé”å®š ({e})ï¼Œæ­£åœ¨æ‰«æå¤‡ç”¨çº¿è·¯...")

        # 2. æš´åŠ›æ‰«æå¤‡ç”¨é€šé“ (é¿å¼€è¾“å‡ºæ‰¬å£°å™¨)
        for idx, name in enumerate(sr.Microphone.list_microphone_names()):
            if any(x in name for x in ["Output", "æ‰¬å£°å™¨", "Speakers", "æ˜ å°„å™¨"]):
                continue
            try:
                mic = sr.Microphone(device_index=idx)
                with mic as source:
                    pass
                console_info(f"âœ… æˆåŠŸæŽ¥ç®¡å¤‡ç”¨å½•éŸ³çº¿è·¯: [{idx}] {name}")
                return mic
            except:
                continue
        return None

    def start(self) -> bool:
        if not VOICE_INTERACTION_AVAILABLE or self.is_running: return False

        # å¯»æ‰¾éº¦å…‹é£Ž
        self.microphone = self._get_working_microphone()
        if not self.microphone:
            console_error("éåŽ†äº†ç³»ç»Ÿä¸­æ‰€æœ‰éŸ³é¢‘è®¾å¤‡ï¼Œå‡æ— æ³•è®¿é—®éº¦å…‹é£Žï¼(è¯·æ£€æŸ¥Windowsç‹¬å æ¨¡å¼è®¾ç½®)")
            return False

        try:
            console_info("æ­£åœ¨æŽ¥é€šéº¦å…‹é£Žå¹¶æ ¡å‡†åº•å™ª...")
            with self.microphone as source:
                self.recognizer.adjust_for_ambient_noise(source, duration=1)
            console_info(f"æ™ºèƒ½è¯­éŸ³ä¸­æž¢å·²å®Œå…¨å¯åŠ¨ï¼Œå”¤é†’è¯: '{self.config.wake_word}'")
        except Exception as e:
            console_error(f"å¯åŠ¨éº¦å…‹é£Žæ—¶å‘ç”Ÿä¸¥é‡å†²çª: {e}")
            return False

        self.stop_event.clear()
        self.is_running = True
        self.interaction_thread = threading.Thread(target=self._interaction_loop, daemon=True)
        self.interaction_thread.start()
        return True

    def stop(self):
        self.is_running = False
        self.stop_event.set()

    def _interaction_loop(self):
        time.sleep(1.0)
        while not self.stop_event.is_set():
            try:
                if not self.microphone: time.sleep(1); continue
                with self.microphone as source:
                    if self.is_active and (time.time() - self.last_wake_time) > self.config.wake_timeout:
                        self.is_active = False
                        console_info("ðŸ’¤ å”¤é†’è¶…æ—¶ï¼Œé‡æ–°è¿›å…¥å¾…æœºæ¨¡å¼ã€‚")

                    if not self.is_active:
                        try:
                            audio = self.recognizer.listen(source, timeout=1, phrase_time_limit=3)
                            text = self._recognize_audio_data(audio)
                            if self.config.wake_word in text:
                                self._handle_wake_word()
                        except sr.WaitTimeoutError:
                            pass
                        except Exception:
                            pass
                    else:
                        try:
                            console_info("ðŸ‘‚ æ­£åœ¨è†å¬æŒ‡ä»¤...")
                            audio = self.recognizer.listen(source, timeout=5, phrase_time_limit=10)
                            text = self._recognize_audio_data(audio)

                            if text:
                                self._route_command(text)
                            else:
                                self.is_active = False
                                console_info("ðŸ’¤ æ²¡å¬æ¸…æŒ‡ä»¤ï¼Œè¿›å…¥å¾…æœºã€‚")
                        except sr.WaitTimeoutError:
                            self.is_active = False
                            console_info("ðŸ’¤ æ²¡å¬åˆ°æŒ‡ä»¤ï¼Œè¿›å…¥å¾…æœºã€‚")
            except Exception:
                time.sleep(1)

    def _handle_wake_word(self):
        stop_tts()
        self.is_active = True
        self.last_wake_time = time.time()
        console_info(f"âœ¨ æ£€æµ‹åˆ°å”¤é†’è¯ï¼")
        speak_async("æˆ‘åœ¨ã€‚")

    def _route_command(self, command: str):
        console_info(f"ðŸ—£ï¸ æ”¶åˆ°è¯­éŸ³è¾“å…¥: {command}")
        rag_engine.save_and_ingest_note(f"ã€ç”¨æˆ·é—®è¯¢ã€‘{time.strftime('%Y-%m-%d %H:%M:%S')}ï¼š{command}")

        if "é€€å‡º" in command or "å…³é—­" in command:
            speak_async("å¥½çš„ï¼Œåœæ­¢è¯­éŸ³æœåŠ¡ã€‚")
            self.is_active = False
            return

        if "è®°ä¸€ä¸‹" in command or "è®°å½•" in command:
            stop_tts()
            note_content = command.split("è®°ä¸€ä¸‹")[-1].split("è®°å½•")[-1].strip(" ï¼Œã€‚ï¼ã€\n")

            if "æˆ‘è¯´å®Œäº†" in note_content:
                final_note = note_content.replace("æˆ‘è¯´å®Œäº†", "").strip(" ï¼Œã€‚ï¼ã€")
                if final_note:
                    rag_engine.save_and_ingest_note(f"ã€é•¿æœŸè®°å¿†ã€‘{time.strftime('%Y-%m-%d %H:%M:%S')}ï¼š{final_note}")
                speak_async("æˆ‘è®°ä¸‹äº†ï¼Œæ‚¨è¿˜æœ‰åˆ«çš„éœ€è¦å—ï¼Ÿ")
                self.is_active = True
                self.last_wake_time = time.time()
                return
            else:
                self._record_long_note(initial_text=note_content)
                return

        self.is_active = False
        if not self.ai_backend: return

        context = rag_engine.retrieve_context(command)
        current_frame = self.get_latest_frame_callback() if self.get_latest_frame_callback else None

        answer = ask_assistant_with_rag(
            frame=current_frame,
            question=command,
            rag_context=context,
            model_name=self.ai_backend.get("model", "qwen-vl-max")
        )
        console_info(f"AIå›žç­”: {answer}")
        rag_engine.save_and_ingest_note(f"ã€AIè§£ç­”ã€‘{time.strftime('%Y-%m-%d %H:%M:%S')}ï¼š{answer}")
        speak_async(answer)

    def _record_long_note(self, initial_text: str = ""):
        speak_async("æ­£åœ¨ä¸ºæ‚¨è®°å½•ï¼Œç»“æŸè¯·è¯´ï¼Œæˆ‘è¯´å®Œäº†ã€‚")
        accumulated = initial_text + "ï¼Œ" if initial_text else ""
        timeout_retries = 0

        while not self.stop_event.is_set():
            try:
                with self.microphone as source:
                    console_info("[è®°å½•ä¸­] æ­£åœ¨å€¾å¬... (è¯´'æˆ‘è¯´å®Œäº†'ç»“æŸ)")
                    audio = self.recognizer.listen(source, timeout=5, phrase_time_limit=15)
                    text = self._recognize_audio_data(audio)

                    if text:
                        console_info(f"âœï¸ å¬å†™ç‰‡æ®µ: {text}")
                        timeout_retries = 0
                        if "æˆ‘è¯´å®Œäº†" in text:
                            final_part = text.replace("æˆ‘è¯´å®Œäº†", "").strip(" ï¼Œã€‚ï¼ã€")
                            if final_part: accumulated += final_part + "ã€‚"
                            break
                        else:
                            accumulated += text + "ï¼Œ"
            except sr.WaitTimeoutError:
                timeout_retries += 1
                if timeout_retries >= 3:
                    speak_async("å½•éŸ³ç­‰å¾…è¶…æ—¶ï¼Œå·²ä¸ºæ‚¨è‡ªåŠ¨ç»“æŸã€‚")
                    break
                continue
            except Exception:
                continue

        if accumulated.strip("ï¼Œã€‚ "):
            rag_engine.save_and_ingest_note(
                f"ã€é•¿æœŸè¯­éŸ³è®°å¿†ã€‘{time.strftime('%Y-%m-%d %H:%M:%S')}ï¼š{accumulated.strip('ï¼Œã€‚ ')}")
            console_info(f"é•¿è¯­éŸ³å·²å®Œæ•´å½’æ¡£å…¥åº“ï¼")

        speak_async("æˆ‘è®°ä¸‹äº†ï¼Œæ‚¨è¿˜æœ‰åˆ«çš„éœ€è¦å—ï¼Ÿ")
        self.is_active = True
        self.last_wake_time = time.time()


_voice_interaction = None


def get_voice_interaction() -> Optional[VoiceInteraction]:
    global _voice_interaction
    if not VOICE_INTERACTION_AVAILABLE: return None
    if _voice_interaction is None:
        _voice_interaction = VoiceInteraction()
    return _voice_interaction