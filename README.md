# LabDetector：智能多模态实验室管家 (V2.3.1)

[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![Ollama](https://img.shields.io/badge/AI_Engine-Ollama-white)](https://ollama.ai/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

LabDetector 是专为微纳流体力学及重型科研实验室打造的**分布式智能多模态管家系统**。本项目将边缘计算（树莓派节点）与高性能中心算力（如 RTX 系列显卡）相结合，支持**动态 QoS 视频并发、RAG 本地知识库、以及离线环境下的语音交互**。

系统旨在为科研人员提供实时的实验状态监控、语音辅助数据记录以及长时实验资产的智能检索服务。


### 核心特性
* **解耦的分布式架构**：
  PC 智算中枢与 Pi 边缘节点在代码层与物理层实现彻底解耦。双端拥有独立运行环境与专属工具链。树莓派端（piside）支持无外部依赖的独立部署，降低了多节点集群的扩展与维护成本。
* **可靠的日志与异常处理机制**：
  内置全局单一真相源（SSOT）版本控制与 5 步沉浸式启动预检（Pre-flight Check）。重构了程序的退出生命周期，通过软硬件中断拦截与系统级进程终止（`os._exit`），确保在正常退出或异常中断时，均能百分百触发日志归档机制，保证实验数据不丢失。
* **动态 QoS 多节点并发**：
  主控 PC 能够根据接入的树莓派数量（1~N 台）动态下发 QoS 指令，自适应调配边缘端帧率（如 5 台设备自动平分 30FPS 带宽），避免实验室无线网络拥塞，确保 PC 端稳定 30FPS 的流畅渲染。
* **基于 RAG 的长时实验记忆**：
  集成基于 FAISS 的轻量化本地向量数据库。语音录入的实验心得可自动转化为 `.txt` 文本文件并实时进行向量化入库，支持对跨时间线的实验数据进行精准的语义关联与检索。
* **边缘语音自愈中枢**：
  将 ASR（自动语音识别）能力下放至树莓派（Pi）端，支持离线的唤醒词监听、指令解析与文本回传。配套抗系统占用的“模型资产自愈管理器”，支持在断网或文件受损时自动重试与恢复。PC 端专职处理重型 RAG 检索与 AI 决策，实现“边缘感知，中心大脑”的系统架构。
* **异步非阻塞视觉推理**：
  视频流渲染与大模型推理流程实现彻底解耦。支持 Ollama 本地私有化视觉大模型（如 Llava/Qwen-VL）满载运行。通过合理的算力分配（GPU 专用于视觉推理，CPU 处理 RAG 与控制逻辑），保障系统的快速响应。

## 更新日志
* **[V2.3.0] 重大架构升级与稳定性重构** (2026-02-24)
  本次更新对系统的底层架构进行了深度重构，全面引入微服务解耦、单一真相源（SSOT）版本控制以及容灾兜底机制。
  * **彻底的分布式解耦架构**：废除全局共享的 `tools` 目录，将工具链下放至 `pcside/tools` 和 `piside/tools`。双端实现物理级解耦，`piside` 模块可独立迁移。
  * **运行兜底机制**：重写退出生命周期，通过 `try...finally` 与 `atexit` 钩子确保任何时刻退出均能保存日志；引入 `os._exit(0)` 解决底层线程残留导致的阻塞；修复 Windows 终端下输入流乱码导致的进程卡死。
  * **启动自检流程 (Launcher)**：重构根目录 `launcher.py`，增加 5 步启动自检；引入算力探针，自动探测 CUDA 环境并在纯 CPU 模式下提供降级运行建议。
  * **模型资产自愈**：新增 `model_downloader.py`，支持缺失资产自动下载；优化 Windows 环境下的文件占用冲突处理。
  * **SSOT 版本控制**：通过根目录 `VERSION` 文件实现全局版本同步，统一标准化日志前缀（`[INFO]`, `[WARN]`, `[ERROR]`）。

## 项目目录结构

```text
Labdetector
 ┣ VERSION                     --- [新增] 全局单一真相源版本控制文件
 ┣ requirements.txt            --- 环境依赖清单
 ┣ setup.py                    --- 项目安装与打包配置
 ┣ config.ini                  --- 全局热更新配置文件
 ┣ launcher.py                 --- [重构] 全局统一启动器 (Pre-flight Check)
 ┣ pcside/                     --- PC 智算中枢端 (挂载 RTX 算力)
 ┃ ┣ main.py                   --- PC 主控核心引擎
 ┃ ┣ tools/                    --- [解耦] PC端专属工具链
 ┃ ┃ ┣ version_manager.py      --- 全局版本号寻路接口
 ┃ ┃ ┣ model_downloader.py     --- 模型资产自愈与静默回收器
 ┃ ┃ ┣ check_gpu.py            --- 算力探针 (含 CPU 降级容错)
 ┃ ┃ ┗ check_mic.py            --- 音频硬件自检
 ┃ ┣ core/                     --- 核心驱动底座
 ┃ ┃ ┣ config.py               --- 配置文件解析器
 ┃ ┃ ┣ logger.py               --- 全局日志系统
 ┃ ┃ ┣ tts.py                  --- 语音合成模块
 ┃ ┃ ┣ ai_backend.py           --- 大模型视觉推理后端 (Ollama/Qwen)
 ┃ ┃ ┗ network.py              --- 网络基础工具
 ┃ ┣ communication/            --- 通信与集群管理模块
 ┃ ┃ ┣ network_scanner.py      --- 局域网拓扑扫描器
 ┃ ┃ ┗ multi_ws_manager.py     --- 多节点 WebSocket 集群管理器
 ┃ ┣ knowledge_base/           --- RAG 知识库系统
 ┃ ┃ ┣ rag_engine.py           --- RAG 核心引擎 (text2vec + FAISS)
 ┃ ┃ ┣ faiss_index/            --- FAISS 向量数据库持久化目录
 ┃ ┃ ┗ docs/                   --- 语音记忆的 TXT 物理存档
 ┃ ┣ voice/                    --- 语音唤醒与交互中枢
 ┃ ┃ ┣ voice_interaction.py    --- 语音交互核心逻辑
 ┃ ┃ ┗ model/                  --- Vosk 离线语音模型资源
 ┃ ┗ log/                      --- 实验运行日志归档目录
 ┗ piside/                     --- Pi 边缘节点端 (高度内聚，独立运行)
   ┣ pisend_receive.py         --- Pi 边缘节点端主控流
   ┣ tools/                    --- [解耦] Pi端专属工具链
   ┃ ┣ version_manager.py
   ┃ ┗ model_downloader.py
   ┗ voice/                    --- 边缘端唤醒模型储备
     ┗ model/                  --- Vosk 离线语音模型资源
```

## 硬件准备与部署清单

为保障大模型推理的响应速度与多路视频流的传输稳定性，建议参考以下硬件配置：

### 1. 中心计算枢纽 (PC 端)
负责全过程的 AI 视觉推理、RAG 向量检索、语音语义解析及 GUI 交互渲染。
* **算力设备 (GPU)**：建议配置 NVIDIA RTX 3090 / 4090 / 5090 或同等具备 24GB 以上显存的计算卡（用于支撑 Ollama 多模态视觉大模型满载运行）。
* **内存 (RAM)**：建议 32GB 及以上，以保障多节点视频帧缓存与本地向量数据库的稳定运行。
* **外设交互**：需配置独立麦克风（用于唤醒交互）及音频输出设备（用于接收系统语音反馈）。
* **操作系统**：Windows 10/11 或 Ubuntu 22.04（需提前配置完善的 CUDA 驱动环境）。

### 2. 边缘监控节点 (树莓派集群)
负责实验点位的视频采集、流媒体压缩传输及本地语音响应。
* **主控板**：Raspberry Pi 4B 或 Raspberry Pi 5。
* **摄像头**：建议使用树莓派官方 CSI 摄像头模块（需兼容 `picamera2` 库）。
* **电源供应**：建议使用官方标准 Type-C 电源（15W / 27W），保障满载并发状态下的供电稳定性。

### 3. 网络环境要求
* **网络拓扑**：所有设备需处于**同一局域网（同一网段）**。
* **带宽保障**：建议部署 Wi-Fi 6 (802.11ax) 标准的千兆路由器。系统内置 QoS 动态调频机制，常规路由设备即可稳定承载 5 台以上边缘节点的并发数据流。

---

## 上手指南
### 0. 克隆项目
```bash
# 1. 克隆项目
git clone https://github.com/labdetector/Labdetector.git
cd Labdetector
# 2. 安装项目依赖 (建议在虚拟环境中执行)
pip install -e .
````

### 1. 中心端部署 (PC)
在项目**根目录**下执行以下命令，完成依赖安装与环境初始化：
```bash
pip install -e .
```
* **AI 视觉后端**：请提前安装 [Ollama](https://ollama.ai/) 运行环境，并拉取默认模型：`ollama run llava:7b-v1.5-q4_K_M`。
* **离线语音模型**：系统内置资产自愈机制，初次启动时将自动下载 Vosk 离线语音模型。若处于纯离线环境，请手动下载 `vosk-model-small-cn-0.22` 并解压至 `pcside/voice/model/`。

### 2. 边缘端部署 (Raspberry Pi)
得益于物理级解耦架构，您只需将项目中的 `piside` 文件夹整体拷贝至边缘设备，进入该目录执行环境安装即可独立运行：
```bash
cd piside
pip install -e .
```

### 3. 配置与集群同步
PC 主控程序首次启动后，将在根目录自动生成 `config.ini` 配置文件。
用户仅需在 PC 端修改该文件中的核心参数（如唤醒词、识别开关等），系统在建立连接后，会**自动将配置参数下发并同步至所有在线的边缘节点**，无需在边缘端进行重复的人工配置。

### 4. 语音交互示例
本系统支持多轮对话与长时记忆录入，基础交互指令参考如下：
1. **状态研判**："小爱同学，现在的流量正常吗？"（系统将结合实时监控画面与知识库输出分析结论）。
2. **数据存档**："小爱同学，记一下，这组样品的流动速度比昨天快了 10%。"（自动转化为文本并存入本地向量库）。
3. **连续录入**：
   > 👨‍🔬 实验员："小爱同学，记一下..."
   > 🤖 系统："好的，请讲。"
   > 👨‍🔬 实验员："...（口述长段落实验观测现象）... 我说完了。"

### 5. 协议与致谢
本项目采用 **MIT** 协议开源。感谢 Ollama、Vosk 以及 LangChain 社区提供的底层技术支撑。